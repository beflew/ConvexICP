{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from data import ModelNet40,download,load_data\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from geomloss import SamplesLoss\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from torch import jit\n",
    "%matplotlib inline\n",
    "import os\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_results_exp = []\n",
    "test_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 2 every 30 epochs\"\"\"\n",
    "    lrt = lr * (0.5 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwu/ConvexICP/data.py:36: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  f = h5py.File(h5_name)\n"
     ]
    }
   ],
   "source": [
    "data = ModelNet40(num_points=1024, partition='train', gaussian_noise=False,\n",
    "                       unseen=False, factor=4)\n",
    "data_test = ModelNet40(num_points=1024, partition='test', gaussian_noise=False,\n",
    "                       unseen=False, factor=4)\n",
    "train_loader = DataLoader(data, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(data_test, batch_size=128, shuffle=True, drop_last=True)\n",
    "rl_loader = DataLoader(data_test, batch_size=1, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_rt_loss(ra,ta,rb,tb):\n",
    "    r_loss = F.mse_loss(ra,rb).item()\n",
    "    t_loss = F.mse_loss(ta,tb).item()\n",
    "    return r_loss, t_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet(nn.Module):\n",
    "    def __init__(self, emb_dims=512):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n",
    "        self.conv3 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n",
    "        self.conv4 = nn.Conv1d(64, 128, kernel_size=1, bias=False)\n",
    "        self.conv5 = nn.Conv1d(128, emb_dims, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.bn5 = nn.BatchNorm1d(emb_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPNet(nn.Module):\n",
    "    def __init__(self, emb_dims=512):\n",
    "        super(CPNet, self).__init__()\n",
    "        self.base_net = PointNet()\n",
    "        self.loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.05)\n",
    "\n",
    "        \n",
    "    def forward(self, x1, x2, R, T):\n",
    "        \n",
    "        trans = torch.matmul(R, x1) + T.unsqueeze(2)\n",
    "        emb1 = self.base_net(trans)\n",
    "        emb2 = self.base_net(x2)\n",
    "        \n",
    "        dist = self.loss(emb1,emb2)\n",
    "\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPEvalNet(nn.Module):\n",
    "    def __init__(self, base_net,batch_size, emb_dims=512):\n",
    "        super(CPEvalNet, self).__init__()\n",
    "        self.base_net = PointNet()\n",
    "        self.base_net.load_state_dict(base_net.state_dict())\n",
    "        for param in self.base_net.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.batch_size = batch_size\n",
    "        self.rotation = nn.Parameter(torch.Tensor(batch_size,3,3))\n",
    "        self.translation = nn.Parameter(torch.Tensor(batch_size,3))\n",
    "        nn.init.kaiming_uniform_(self.rotation, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.translation, a=math.sqrt(5))\n",
    "        self.loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.05)\n",
    "\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        trans = torch.matmul(self.rotation, x1) + self.translation.unsqueeze(2)\n",
    "        emb1 = self.base_net(trans)\n",
    "        emb2 = self.base_net(x2)\n",
    "        \n",
    "        dist = self.loss(emb1,emb2)\n",
    "\n",
    "        return dist\n",
    "    \n",
    "    def cal_emb(self,x1,x2):\n",
    "        trans = torch.matmul(self.rotation, x1) + self.translation.unsqueeze(2)\n",
    "        emb1 = self.base_net(trans)\n",
    "        emb2 = self.base_net(x2)\n",
    "        return emb1,emb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = torch.load(\"no_pert_base.mdl\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_loss(output, target):\n",
    "    loss = torch.mean(output)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rt_learning(model, device, src, target, rotation_ab, translation_ab, optimizer,criterion,epoch,n_batch = 40):\n",
    "    r_losses = []\n",
    "    t_losses = []\n",
    "    for _ in range(n_batch):\n",
    "        model.train()\n",
    "        t1 = datetime.now()\n",
    "        src = src.to(device)\n",
    "        target = target.to(device)\n",
    "        rotation_ab = rotation_ab.to(device)\n",
    "        translation_ab = translation_ab.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_train = model(src,target)\n",
    "        loss = criterion(output_train, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        r_loss,t_loss = cal_rt_loss(model.rotation, model.translation,rotation_ab, translation_ab)\n",
    "        r_losses.append(r_loss)\n",
    "        t_losses.append(t_loss)\n",
    "    return r_losses, t_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_losses = []\n",
    "t_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tRotation_Loss: 5519.810059\tTranslation_Loss: 0.079069\tTime: 0.03\n",
      "Train Epoch: 2 \tRotation_Loss: 19877.384766\tTranslation_Loss: 0.078813\tTime: 0.02\n",
      "Train Epoch: 3 \tRotation_Loss: 40124.328125\tTranslation_Loss: 0.078457\tTime: 0.02\n",
      "Train Epoch: 4 \tRotation_Loss: 63859.472656\tTranslation_Loss: 0.078031\tTime: 0.02\n",
      "Train Epoch: 5 \tRotation_Loss: 89161.140625\tTranslation_Loss: 0.077562\tTime: 0.02\n",
      "Train Epoch: 6 \tRotation_Loss: 114523.625000\tTranslation_Loss: 0.077080\tTime: 0.02\n",
      "Train Epoch: 7 \tRotation_Loss: 138798.859375\tTranslation_Loss: 0.076610\tTime: 0.02\n",
      "Train Epoch: 8 \tRotation_Loss: 161142.812500\tTranslation_Loss: 0.076175\tTime: 0.02\n",
      "Train Epoch: 9 \tRotation_Loss: 180967.390625\tTranslation_Loss: 0.075795\tTime: 0.02\n",
      "Train Epoch: 10 \tRotation_Loss: 197897.062500\tTranslation_Loss: 0.075489\tTime: 0.02\n",
      "Train Epoch: 11 \tRotation_Loss: 211730.328125\tTranslation_Loss: 0.075269\tTime: 0.02\n",
      "Train Epoch: 12 \tRotation_Loss: 222405.750000\tTranslation_Loss: 0.075147\tTime: 0.02\n",
      "Train Epoch: 13 \tRotation_Loss: 229972.078125\tTranslation_Loss: 0.075130\tTime: 0.02\n",
      "Train Epoch: 14 \tRotation_Loss: 234562.718750\tTranslation_Loss: 0.075222\tTime: 0.02\n",
      "Train Epoch: 15 \tRotation_Loss: 236373.609375\tTranslation_Loss: 0.075425\tTime: 0.02\n",
      "Train Epoch: 16 \tRotation_Loss: 235644.500000\tTranslation_Loss: 0.075739\tTime: 0.02\n",
      "Train Epoch: 17 \tRotation_Loss: 232643.062500\tTranslation_Loss: 0.076160\tTime: 0.02\n",
      "Train Epoch: 18 \tRotation_Loss: 227652.218750\tTranslation_Loss: 0.076685\tTime: 0.02\n",
      "Train Epoch: 19 \tRotation_Loss: 220959.453125\tTranslation_Loss: 0.077307\tTime: 0.02\n",
      "Train Epoch: 20 \tRotation_Loss: 212848.453125\tTranslation_Loss: 0.078018\tTime: 0.02\n",
      "Train Epoch: 21 \tRotation_Loss: 203592.578125\tTranslation_Loss: 0.078810\tTime: 0.02\n",
      "Train Epoch: 22 \tRotation_Loss: 193450.046875\tTranslation_Loss: 0.079675\tTime: 0.02\n",
      "Train Epoch: 23 \tRotation_Loss: 182660.359375\tTranslation_Loss: 0.080603\tTime: 0.02\n",
      "Train Epoch: 24 \tRotation_Loss: 171442.000000\tTranslation_Loss: 0.081584\tTime: 0.02\n",
      "Train Epoch: 25 \tRotation_Loss: 159990.953125\tTranslation_Loss: 0.082608\tTime: 0.02\n",
      "Train Epoch: 26 \tRotation_Loss: 148480.390625\tTranslation_Loss: 0.083665\tTime: 0.02\n",
      "Train Epoch: 27 \tRotation_Loss: 137060.531250\tTranslation_Loss: 0.084747\tTime: 0.02\n",
      "Train Epoch: 28 \tRotation_Loss: 125859.414062\tTranslation_Loss: 0.085845\tTime: 0.02\n",
      "Train Epoch: 29 \tRotation_Loss: 114983.820312\tTranslation_Loss: 0.086949\tTime: 0.02\n",
      "Train Epoch: 30 \tRotation_Loss: 104520.640625\tTranslation_Loss: 0.088052\tTime: 0.02\n",
      "Train Epoch: 31 \tRotation_Loss: 94538.296875\tTranslation_Loss: 0.089146\tTime: 0.02\n",
      "Train Epoch: 32 \tRotation_Loss: 85088.390625\tTranslation_Loss: 0.090226\tTime: 0.02\n",
      "Train Epoch: 33 \tRotation_Loss: 76207.343750\tTranslation_Loss: 0.091284\tTime: 0.02\n",
      "Train Epoch: 34 \tRotation_Loss: 67917.914062\tTranslation_Loss: 0.092315\tTime: 0.02\n",
      "Train Epoch: 35 \tRotation_Loss: 60230.757812\tTranslation_Loss: 0.093316\tTime: 0.02\n",
      "Train Epoch: 36 \tRotation_Loss: 53146.140625\tTranslation_Loss: 0.094281\tTime: 0.02\n",
      "Train Epoch: 37 \tRotation_Loss: 46655.832031\tTranslation_Loss: 0.095207\tTime: 0.02\n",
      "Train Epoch: 38 \tRotation_Loss: 40744.656250\tTranslation_Loss: 0.096092\tTime: 0.02\n",
      "Train Epoch: 39 \tRotation_Loss: 35391.812500\tTranslation_Loss: 0.096934\tTime: 0.02\n",
      "Train Epoch: 40 \tRotation_Loss: 30572.160156\tTranslation_Loss: 0.097730\tTime: 0.02\n",
      "Train Epoch: 41 \tRotation_Loss: 26257.259766\tTranslation_Loss: 0.098480\tTime: 0.02\n",
      "Train Epoch: 42 \tRotation_Loss: 22416.191406\tTranslation_Loss: 0.099183\tTime: 0.02\n",
      "Train Epoch: 43 \tRotation_Loss: 19016.503906\tTranslation_Loss: 0.099839\tTime: 0.02\n",
      "Train Epoch: 44 \tRotation_Loss: 16025.038086\tTranslation_Loss: 0.100448\tTime: 0.02\n",
      "Train Epoch: 45 \tRotation_Loss: 13408.609375\tTranslation_Loss: 0.101010\tTime: 0.02\n",
      "Train Epoch: 46 \tRotation_Loss: 11134.513672\tTranslation_Loss: 0.101527\tTime: 0.02\n",
      "Train Epoch: 47 \tRotation_Loss: 9170.917969\tTranslation_Loss: 0.102000\tTime: 0.02\n",
      "Train Epoch: 48 \tRotation_Loss: 7487.170898\tTranslation_Loss: 0.102429\tTime: 0.02\n",
      "Train Epoch: 49 \tRotation_Loss: 6054.069336\tTranslation_Loss: 0.102816\tTime: 0.02\n",
      "Train Epoch: 50 \tRotation_Loss: 4844.019531\tTranslation_Loss: 0.103163\tTime: 0.02\n",
      "Train Epoch: 51 \tRotation_Loss: 3831.110352\tTranslation_Loss: 0.103472\tTime: 0.02\n",
      "Train Epoch: 52 \tRotation_Loss: 2991.273926\tTranslation_Loss: 0.103744\tTime: 0.02\n",
      "Train Epoch: 53 \tRotation_Loss: 2302.340820\tTranslation_Loss: 0.103982\tTime: 0.02\n",
      "Train Epoch: 54 \tRotation_Loss: 1744.145386\tTranslation_Loss: 0.104187\tTime: 0.02\n",
      "Train Epoch: 55 \tRotation_Loss: 1298.443970\tTranslation_Loss: 0.104361\tTime: 0.02\n",
      "Train Epoch: 56 \tRotation_Loss: 948.170471\tTranslation_Loss: 0.104507\tTime: 0.02\n",
      "Train Epoch: 57 \tRotation_Loss: 677.895691\tTranslation_Loss: 0.104626\tTime: 0.02\n",
      "Train Epoch: 58 \tRotation_Loss: 475.525452\tTranslation_Loss: 0.104720\tTime: 0.02\n",
      "Train Epoch: 59 \tRotation_Loss: 330.885315\tTranslation_Loss: 0.104792\tTime: 0.02\n",
      "Train Epoch: 60 \tRotation_Loss: 232.941132\tTranslation_Loss: 0.104842\tTime: 0.02\n",
      "Train Epoch: 61 \tRotation_Loss: 171.285736\tTranslation_Loss: 0.104873\tTime: 0.02\n",
      "Train Epoch: 62 \tRotation_Loss: 137.488312\tTranslation_Loss: 0.104886\tTime: 0.02\n",
      "Train Epoch: 63 \tRotation_Loss: 123.367256\tTranslation_Loss: 0.104883\tTime: 0.02\n",
      "Train Epoch: 64 \tRotation_Loss: 125.667168\tTranslation_Loss: 0.104866\tTime: 0.02\n",
      "Train Epoch: 65 \tRotation_Loss: 142.483047\tTranslation_Loss: 0.104837\tTime: 0.02\n",
      "Train Epoch: 66 \tRotation_Loss: 168.024948\tTranslation_Loss: 0.104796\tTime: 0.02\n",
      "Train Epoch: 67 \tRotation_Loss: 198.328079\tTranslation_Loss: 0.104745\tTime: 0.02\n",
      "Train Epoch: 68 \tRotation_Loss: 231.759979\tTranslation_Loss: 0.104686\tTime: 0.02\n",
      "Train Epoch: 69 \tRotation_Loss: 266.264496\tTranslation_Loss: 0.104620\tTime: 0.02\n",
      "Train Epoch: 70 \tRotation_Loss: 301.469299\tTranslation_Loss: 0.104547\tTime: 0.02\n",
      "Train Epoch: 71 \tRotation_Loss: 336.652130\tTranslation_Loss: 0.104469\tTime: 0.02\n",
      "Train Epoch: 72 \tRotation_Loss: 370.252594\tTranslation_Loss: 0.104386\tTime: 0.02\n",
      "Train Epoch: 73 \tRotation_Loss: 400.376221\tTranslation_Loss: 0.104301\tTime: 0.02\n",
      "Train Epoch: 74 \tRotation_Loss: 425.903595\tTranslation_Loss: 0.104212\tTime: 0.02\n",
      "Train Epoch: 75 \tRotation_Loss: 446.866547\tTranslation_Loss: 0.104122\tTime: 0.02\n",
      "Train Epoch: 76 \tRotation_Loss: 463.722656\tTranslation_Loss: 0.104030\tTime: 0.02\n",
      "Train Epoch: 77 \tRotation_Loss: 476.605682\tTranslation_Loss: 0.103938\tTime: 0.02\n",
      "Train Epoch: 78 \tRotation_Loss: 486.121490\tTranslation_Loss: 0.103846\tTime: 0.02\n",
      "Train Epoch: 79 \tRotation_Loss: 492.650055\tTranslation_Loss: 0.103754\tTime: 0.02\n",
      "Train Epoch: 80 \tRotation_Loss: 495.960388\tTranslation_Loss: 0.103663\tTime: 0.02\n",
      "Train Epoch: 81 \tRotation_Loss: 495.698303\tTranslation_Loss: 0.103573\tTime: 0.03\n",
      "Train Epoch: 82 \tRotation_Loss: 491.695312\tTranslation_Loss: 0.103484\tTime: 0.02\n",
      "Train Epoch: 83 \tRotation_Loss: 484.208984\tTranslation_Loss: 0.103398\tTime: 0.02\n",
      "Train Epoch: 84 \tRotation_Loss: 473.843750\tTranslation_Loss: 0.103313\tTime: 0.02\n",
      "Train Epoch: 85 \tRotation_Loss: 461.260376\tTranslation_Loss: 0.103231\tTime: 0.02\n",
      "Train Epoch: 86 \tRotation_Loss: 446.988922\tTranslation_Loss: 0.103152\tTime: 0.02\n",
      "Train Epoch: 87 \tRotation_Loss: 431.305969\tTranslation_Loss: 0.103074\tTime: 0.02\n",
      "Train Epoch: 88 \tRotation_Loss: 414.385864\tTranslation_Loss: 0.103000\tTime: 0.02\n",
      "Train Epoch: 89 \tRotation_Loss: 396.418121\tTranslation_Loss: 0.102929\tTime: 0.02\n",
      "Train Epoch: 90 \tRotation_Loss: 377.614685\tTranslation_Loss: 0.102860\tTime: 0.02\n",
      "Train Epoch: 91 \tRotation_Loss: 358.169586\tTranslation_Loss: 0.102795\tTime: 0.02\n",
      "Train Epoch: 92 \tRotation_Loss: 338.281647\tTranslation_Loss: 0.102732\tTime: 0.02\n",
      "Train Epoch: 93 \tRotation_Loss: 318.097229\tTranslation_Loss: 0.102673\tTime: 0.02\n",
      "Train Epoch: 94 \tRotation_Loss: 297.804138\tTranslation_Loss: 0.102616\tTime: 0.02\n",
      "Train Epoch: 95 \tRotation_Loss: 277.608307\tTranslation_Loss: 0.102563\tTime: 0.02\n",
      "Train Epoch: 96 \tRotation_Loss: 257.659912\tTranslation_Loss: 0.102512\tTime: 0.02\n",
      "Train Epoch: 97 \tRotation_Loss: 238.103516\tTranslation_Loss: 0.102464\tTime: 0.02\n",
      "Train Epoch: 98 \tRotation_Loss: 219.076797\tTranslation_Loss: 0.102420\tTime: 0.02\n",
      "Train Epoch: 99 \tRotation_Loss: 200.718781\tTranslation_Loss: 0.102378\tTime: 0.02\n",
      "Train Epoch: 100 \tRotation_Loss: 183.296829\tTranslation_Loss: 0.102338\tTime: 0.02\n",
      "Train Epoch: 101 \tRotation_Loss: 166.872574\tTranslation_Loss: 0.102302\tTime: 0.02\n",
      "Train Epoch: 102 \tRotation_Loss: 151.370712\tTranslation_Loss: 0.102268\tTime: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 103 \tRotation_Loss: 137.350830\tTranslation_Loss: 0.102236\tTime: 0.02\n",
      "Train Epoch: 104 \tRotation_Loss: 124.652901\tTranslation_Loss: 0.102207\tTime: 0.02\n",
      "Train Epoch: 105 \tRotation_Loss: 113.344513\tTranslation_Loss: 0.102180\tTime: 0.02\n",
      "Train Epoch: 106 \tRotation_Loss: 103.710365\tTranslation_Loss: 0.102155\tTime: 0.02\n",
      "Train Epoch: 107 \tRotation_Loss: 95.264542\tTranslation_Loss: 0.102132\tTime: 0.02\n",
      "Train Epoch: 108 \tRotation_Loss: 87.795464\tTranslation_Loss: 0.102111\tTime: 0.02\n",
      "Train Epoch: 109 \tRotation_Loss: 81.553673\tTranslation_Loss: 0.102093\tTime: 0.02\n",
      "Train Epoch: 110 \tRotation_Loss: 76.335136\tTranslation_Loss: 0.102075\tTime: 0.02\n",
      "Train Epoch: 111 \tRotation_Loss: 71.553619\tTranslation_Loss: 0.102060\tTime: 0.02\n",
      "Train Epoch: 112 \tRotation_Loss: 67.211494\tTranslation_Loss: 0.102046\tTime: 0.02\n",
      "Train Epoch: 113 \tRotation_Loss: 63.591675\tTranslation_Loss: 0.102034\tTime: 0.02\n",
      "Train Epoch: 114 \tRotation_Loss: 61.760025\tTranslation_Loss: 0.102023\tTime: 0.02\n",
      "Train Epoch: 115 \tRotation_Loss: 61.106209\tTranslation_Loss: 0.102014\tTime: 0.02\n",
      "Train Epoch: 116 \tRotation_Loss: 60.941311\tTranslation_Loss: 0.102005\tTime: 0.02\n",
      "Train Epoch: 117 \tRotation_Loss: 61.119156\tTranslation_Loss: 0.101998\tTime: 0.03\n",
      "Train Epoch: 118 \tRotation_Loss: 62.122150\tTranslation_Loss: 0.101992\tTime: 0.02\n",
      "Train Epoch: 119 \tRotation_Loss: 63.611748\tTranslation_Loss: 0.101987\tTime: 0.02\n",
      "Train Epoch: 120 \tRotation_Loss: 65.168129\tTranslation_Loss: 0.101983\tTime: 0.02\n",
      "Train Epoch: 121 \tRotation_Loss: 66.579712\tTranslation_Loss: 0.101980\tTime: 0.02\n",
      "Train Epoch: 122 \tRotation_Loss: 68.521866\tTranslation_Loss: 0.101977\tTime: 0.03\n",
      "Train Epoch: 123 \tRotation_Loss: 70.347649\tTranslation_Loss: 0.101975\tTime: 0.02\n",
      "Train Epoch: 124 \tRotation_Loss: 71.576180\tTranslation_Loss: 0.101974\tTime: 0.02\n",
      "Train Epoch: 125 \tRotation_Loss: 72.500587\tTranslation_Loss: 0.101973\tTime: 0.02\n",
      "Train Epoch: 126 \tRotation_Loss: 73.101662\tTranslation_Loss: 0.101973\tTime: 0.02\n",
      "Train Epoch: 127 \tRotation_Loss: 73.301056\tTranslation_Loss: 0.101974\tTime: 0.02\n",
      "Train Epoch: 128 \tRotation_Loss: 73.491096\tTranslation_Loss: 0.101975\tTime: 0.02\n",
      "Train Epoch: 129 \tRotation_Loss: 73.310036\tTranslation_Loss: 0.101976\tTime: 0.02\n",
      "Train Epoch: 130 \tRotation_Loss: 72.608505\tTranslation_Loss: 0.101978\tTime: 0.02\n",
      "Train Epoch: 131 \tRotation_Loss: 71.736130\tTranslation_Loss: 0.101980\tTime: 0.02\n",
      "Train Epoch: 132 \tRotation_Loss: 70.728271\tTranslation_Loss: 0.101983\tTime: 0.02\n",
      "Train Epoch: 133 \tRotation_Loss: 69.410263\tTranslation_Loss: 0.101985\tTime: 0.02\n",
      "Train Epoch: 134 \tRotation_Loss: 67.880432\tTranslation_Loss: 0.101988\tTime: 0.02\n",
      "Train Epoch: 135 \tRotation_Loss: 66.269119\tTranslation_Loss: 0.101991\tTime: 0.02\n",
      "Train Epoch: 136 \tRotation_Loss: 64.630386\tTranslation_Loss: 0.101994\tTime: 0.02\n",
      "Train Epoch: 137 \tRotation_Loss: 62.576797\tTranslation_Loss: 0.101997\tTime: 0.02\n",
      "Train Epoch: 138 \tRotation_Loss: 60.238972\tTranslation_Loss: 0.102000\tTime: 0.02\n",
      "Train Epoch: 139 \tRotation_Loss: 57.990322\tTranslation_Loss: 0.102004\tTime: 0.02\n",
      "Train Epoch: 140 \tRotation_Loss: 56.120972\tTranslation_Loss: 0.102007\tTime: 0.02\n",
      "Train Epoch: 141 \tRotation_Loss: 55.309563\tTranslation_Loss: 0.102010\tTime: 0.02\n",
      "Train Epoch: 142 \tRotation_Loss: 54.798084\tTranslation_Loss: 0.102014\tTime: 0.02\n",
      "Train Epoch: 143 \tRotation_Loss: 55.296741\tTranslation_Loss: 0.102017\tTime: 0.02\n",
      "Train Epoch: 144 \tRotation_Loss: 55.908104\tTranslation_Loss: 0.102020\tTime: 0.02\n",
      "Train Epoch: 145 \tRotation_Loss: 57.631458\tTranslation_Loss: 0.102024\tTime: 0.02\n",
      "Train Epoch: 146 \tRotation_Loss: 61.809700\tTranslation_Loss: 0.102027\tTime: 0.02\n",
      "Train Epoch: 147 \tRotation_Loss: 66.229561\tTranslation_Loss: 0.102030\tTime: 0.02\n",
      "Train Epoch: 148 \tRotation_Loss: 81.387733\tTranslation_Loss: 0.102033\tTime: 0.02\n",
      "Train Epoch: 149 \tRotation_Loss: 118.359619\tTranslation_Loss: 0.102036\tTime: 0.02\n",
      "Train Epoch: 150 \tRotation_Loss: 175.700409\tTranslation_Loss: 0.102039\tTime: 0.02\n",
      "Train Epoch: 151 \tRotation_Loss: 246.279129\tTranslation_Loss: 0.102042\tTime: 0.02\n",
      "Train Epoch: 152 \tRotation_Loss: 326.152740\tTranslation_Loss: 0.102045\tTime: 0.02\n",
      "Train Epoch: 153 \tRotation_Loss: 411.525513\tTranslation_Loss: 0.102048\tTime: 0.02\n",
      "Train Epoch: 154 \tRotation_Loss: 498.028748\tTranslation_Loss: 0.102050\tTime: 0.02\n",
      "Train Epoch: 155 \tRotation_Loss: 581.701050\tTranslation_Loss: 0.102052\tTime: 0.02\n",
      "Train Epoch: 156 \tRotation_Loss: 659.465820\tTranslation_Loss: 0.102055\tTime: 0.02\n",
      "Train Epoch: 157 \tRotation_Loss: 728.876221\tTranslation_Loss: 0.102057\tTime: 0.02\n",
      "Train Epoch: 158 \tRotation_Loss: 788.385315\tTranslation_Loss: 0.102059\tTime: 0.02\n",
      "Train Epoch: 159 \tRotation_Loss: 837.264893\tTranslation_Loss: 0.102060\tTime: 0.02\n",
      "Train Epoch: 160 \tRotation_Loss: 875.427490\tTranslation_Loss: 0.102062\tTime: 0.02\n",
      "Train Epoch: 161 \tRotation_Loss: 902.802429\tTranslation_Loss: 0.102064\tTime: 0.02\n",
      "Train Epoch: 162 \tRotation_Loss: 919.576050\tTranslation_Loss: 0.102065\tTime: 0.02\n",
      "Train Epoch: 163 \tRotation_Loss: 926.228088\tTranslation_Loss: 0.102067\tTime: 0.02\n",
      "Train Epoch: 164 \tRotation_Loss: 923.458984\tTranslation_Loss: 0.102068\tTime: 0.02\n",
      "Train Epoch: 165 \tRotation_Loss: 912.143372\tTranslation_Loss: 0.102069\tTime: 0.02\n",
      "Train Epoch: 166 \tRotation_Loss: 893.238403\tTranslation_Loss: 0.102070\tTime: 0.02\n",
      "Train Epoch: 167 \tRotation_Loss: 867.736633\tTranslation_Loss: 0.102071\tTime: 0.02\n",
      "Train Epoch: 168 \tRotation_Loss: 836.668518\tTranslation_Loss: 0.102072\tTime: 0.02\n",
      "Train Epoch: 169 \tRotation_Loss: 801.061462\tTranslation_Loss: 0.102073\tTime: 0.02\n",
      "Train Epoch: 170 \tRotation_Loss: 761.902283\tTranslation_Loss: 0.102074\tTime: 0.02\n",
      "Train Epoch: 171 \tRotation_Loss: 720.111938\tTranslation_Loss: 0.102074\tTime: 0.02\n",
      "Train Epoch: 172 \tRotation_Loss: 676.546570\tTranslation_Loss: 0.102075\tTime: 0.02\n",
      "Train Epoch: 173 \tRotation_Loss: 631.974426\tTranslation_Loss: 0.102076\tTime: 0.02\n",
      "Train Epoch: 174 \tRotation_Loss: 587.078796\tTranslation_Loss: 0.102076\tTime: 0.02\n",
      "Train Epoch: 175 \tRotation_Loss: 542.449524\tTranslation_Loss: 0.102077\tTime: 0.02\n",
      "Train Epoch: 176 \tRotation_Loss: 498.604431\tTranslation_Loss: 0.102077\tTime: 0.02\n",
      "Train Epoch: 177 \tRotation_Loss: 455.976074\tTranslation_Loss: 0.102077\tTime: 0.02\n",
      "Train Epoch: 178 \tRotation_Loss: 414.923187\tTranslation_Loss: 0.102078\tTime: 0.02\n",
      "Train Epoch: 179 \tRotation_Loss: 375.730957\tTranslation_Loss: 0.102078\tTime: 0.02\n",
      "Train Epoch: 180 \tRotation_Loss: 338.610840\tTranslation_Loss: 0.102078\tTime: 0.02\n",
      "Train Epoch: 181 \tRotation_Loss: 303.724274\tTranslation_Loss: 0.102078\tTime: 0.02\n",
      "Train Epoch: 182 \tRotation_Loss: 271.185028\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 183 \tRotation_Loss: 241.043411\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 184 \tRotation_Loss: 213.315994\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 185 \tRotation_Loss: 187.978928\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 186 \tRotation_Loss: 164.950668\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 187 \tRotation_Loss: 144.157486\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 188 \tRotation_Loss: 125.589882\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 189 \tRotation_Loss: 109.008698\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 190 \tRotation_Loss: 94.270081\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 191 \tRotation_Loss: 81.355850\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 192 \tRotation_Loss: 69.922157\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 193 \tRotation_Loss: 59.831734\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 194 \tRotation_Loss: 51.071415\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 195 \tRotation_Loss: 43.632603\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 196 \tRotation_Loss: 37.502163\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 197 \tRotation_Loss: 32.379101\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 198 \tRotation_Loss: 28.227076\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 199 \tRotation_Loss: 25.082558\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 200 \tRotation_Loss: 22.659328\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 201 \tRotation_Loss: 20.750904\tTranslation_Loss: 0.102080\tTime: 0.02\n",
      "Train Epoch: 202 \tRotation_Loss: 19.285301\tTranslation_Loss: 0.102080\tTime: 0.02\n",
      "Train Epoch: 203 \tRotation_Loss: 18.028177\tTranslation_Loss: 0.102080\tTime: 0.02\n",
      "Train Epoch: 204 \tRotation_Loss: 17.063444\tTranslation_Loss: 0.102081\tTime: 0.02\n",
      "Train Epoch: 205 \tRotation_Loss: 16.558340\tTranslation_Loss: 0.102081\tTime: 0.02\n",
      "Train Epoch: 206 \tRotation_Loss: 16.486254\tTranslation_Loss: 0.102081\tTime: 0.02\n",
      "Train Epoch: 207 \tRotation_Loss: 17.282169\tTranslation_Loss: 0.102081\tTime: 0.02\n",
      "Train Epoch: 208 \tRotation_Loss: 19.521395\tTranslation_Loss: 0.102081\tTime: 0.02\n",
      "Train Epoch: 209 \tRotation_Loss: 22.771753\tTranslation_Loss: 0.102081\tTime: 0.02\n",
      "Train Epoch: 210 \tRotation_Loss: 26.030169\tTranslation_Loss: 0.102081\tTime: 0.02\n",
      "Train Epoch: 211 \tRotation_Loss: 29.266632\tTranslation_Loss: 0.102081\tTime: 0.02\n",
      "Train Epoch: 212 \tRotation_Loss: 32.709278\tTranslation_Loss: 0.102081\tTime: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 213 \tRotation_Loss: 36.210506\tTranslation_Loss: 0.102081\tTime: 0.02\n",
      "Train Epoch: 214 \tRotation_Loss: 39.536873\tTranslation_Loss: 0.102080\tTime: 0.02\n",
      "Train Epoch: 215 \tRotation_Loss: 42.900242\tTranslation_Loss: 0.102080\tTime: 0.02\n",
      "Train Epoch: 216 \tRotation_Loss: 45.840103\tTranslation_Loss: 0.102080\tTime: 0.02\n",
      "Train Epoch: 217 \tRotation_Loss: 48.164558\tTranslation_Loss: 0.102080\tTime: 0.02\n",
      "Train Epoch: 218 \tRotation_Loss: 50.027943\tTranslation_Loss: 0.102080\tTime: 0.02\n",
      "Train Epoch: 219 \tRotation_Loss: 51.456352\tTranslation_Loss: 0.102080\tTime: 0.02\n",
      "Train Epoch: 220 \tRotation_Loss: 52.450825\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 221 \tRotation_Loss: 52.995197\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 222 \tRotation_Loss: 52.995380\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 223 \tRotation_Loss: 52.560200\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 224 \tRotation_Loss: 51.822041\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 225 \tRotation_Loss: 50.764362\tTranslation_Loss: 0.102079\tTime: 0.02\n",
      "Train Epoch: 226 \tRotation_Loss: 49.392776\tTranslation_Loss: 0.102078\tTime: 0.02\n",
      "Train Epoch: 227 \tRotation_Loss: 47.794750\tTranslation_Loss: 0.102078\tTime: 0.02\n",
      "Train Epoch: 228 \tRotation_Loss: 45.954308\tTranslation_Loss: 0.102078\tTime: 0.02\n",
      "Train Epoch: 229 \tRotation_Loss: 44.023945\tTranslation_Loss: 0.102078\tTime: 0.02\n",
      "Train Epoch: 230 \tRotation_Loss: 41.975811\tTranslation_Loss: 0.102077\tTime: 0.02\n",
      "Train Epoch: 231 \tRotation_Loss: 39.926315\tTranslation_Loss: 0.102077\tTime: 0.02\n",
      "Train Epoch: 232 \tRotation_Loss: 37.923420\tTranslation_Loss: 0.102077\tTime: 0.02\n",
      "Train Epoch: 233 \tRotation_Loss: 35.970142\tTranslation_Loss: 0.102076\tTime: 0.02\n",
      "Train Epoch: 234 \tRotation_Loss: 34.051228\tTranslation_Loss: 0.102076\tTime: 0.02\n",
      "Train Epoch: 235 \tRotation_Loss: 32.169605\tTranslation_Loss: 0.102076\tTime: 0.02\n",
      "Train Epoch: 236 \tRotation_Loss: 30.340237\tTranslation_Loss: 0.102076\tTime: 0.02\n",
      "Train Epoch: 237 \tRotation_Loss: 28.503296\tTranslation_Loss: 0.102075\tTime: 0.02\n",
      "Train Epoch: 238 \tRotation_Loss: 26.710903\tTranslation_Loss: 0.102075\tTime: 0.02\n",
      "Train Epoch: 239 \tRotation_Loss: 25.053045\tTranslation_Loss: 0.102074\tTime: 0.02\n",
      "Train Epoch: 240 \tRotation_Loss: 23.533360\tTranslation_Loss: 0.102074\tTime: 0.02\n",
      "Train Epoch: 241 \tRotation_Loss: 22.285238\tTranslation_Loss: 0.102074\tTime: 0.02\n",
      "Train Epoch: 242 \tRotation_Loss: 21.470484\tTranslation_Loss: 0.102074\tTime: 0.02\n",
      "Train Epoch: 243 \tRotation_Loss: 21.991793\tTranslation_Loss: 0.102074\tTime: 0.02\n",
      "Train Epoch: 244 \tRotation_Loss: 24.715834\tTranslation_Loss: 0.102075\tTime: 0.02\n",
      "Train Epoch: 245 \tRotation_Loss: 29.656799\tTranslation_Loss: 0.102075\tTime: 0.02\n",
      "Train Epoch: 246 \tRotation_Loss: 56.144314\tTranslation_Loss: 0.102075\tTime: 0.02\n",
      "Train Epoch: 247 \tRotation_Loss: 114.180855\tTranslation_Loss: 0.102075\tTime: 0.02\n",
      "Train Epoch: 248 \tRotation_Loss: 402.686615\tTranslation_Loss: 0.102075\tTime: 0.02\n",
      "Train Epoch: 249 \tRotation_Loss: 1034.070435\tTranslation_Loss: 0.102075\tTime: 0.02\n",
      "Train Epoch: 1 \tRotation_Loss: 452362.937500\tTranslation_Loss: 0.113088\tTime: 0.02\n",
      "Train Epoch: 2 \tRotation_Loss: 1624884.625000\tTranslation_Loss: 0.112603\tTime: 0.02\n",
      "Train Epoch: 3 \tRotation_Loss: 3277013.750000\tTranslation_Loss: 0.111939\tTime: 0.02\n",
      "Train Epoch: 4 \tRotation_Loss: 5212950.500000\tTranslation_Loss: 0.111129\tTime: 0.02\n",
      "Train Epoch: 5 \tRotation_Loss: 7276043.500000\tTranslation_Loss: 0.110206\tTime: 0.02\n",
      "Train Epoch: 6 \tRotation_Loss: 9343595.000000\tTranslation_Loss: 0.109203\tTime: 0.02\n",
      "Train Epoch: 7 \tRotation_Loss: 11322070.000000\tTranslation_Loss: 0.108146\tTime: 0.02\n",
      "Train Epoch: 8 \tRotation_Loss: 13142745.000000\tTranslation_Loss: 0.107064\tTime: 0.02\n",
      "Train Epoch: 9 \tRotation_Loss: 14757757.000000\tTranslation_Loss: 0.105980\tTime: 0.02\n",
      "Train Epoch: 10 \tRotation_Loss: 16136569.000000\tTranslation_Loss: 0.104915\tTime: 0.02\n",
      "Train Epoch: 11 \tRotation_Loss: 17262826.000000\tTranslation_Loss: 0.103886\tTime: 0.02\n",
      "Train Epoch: 12 \tRotation_Loss: 18131582.000000\tTranslation_Loss: 0.102908\tTime: 0.02\n",
      "Train Epoch: 13 \tRotation_Loss: 18746868.000000\tTranslation_Loss: 0.101992\tTime: 0.02\n",
      "Train Epoch: 14 \tRotation_Loss: 19119602.000000\tTranslation_Loss: 0.101148\tTime: 0.02\n",
      "Train Epoch: 15 \tRotation_Loss: 19265786.000000\tTranslation_Loss: 0.100381\tTime: 0.02\n",
      "Train Epoch: 16 \tRotation_Loss: 19204984.000000\tTranslation_Loss: 0.099697\tTime: 0.02\n",
      "Train Epoch: 17 \tRotation_Loss: 18959040.000000\tTranslation_Loss: 0.099098\tTime: 0.02\n",
      "Train Epoch: 18 \tRotation_Loss: 18551026.000000\tTranslation_Loss: 0.098584\tTime: 0.02\n",
      "Train Epoch: 19 \tRotation_Loss: 18004378.000000\tTranslation_Loss: 0.098153\tTime: 0.02\n",
      "Train Epoch: 20 \tRotation_Loss: 17342222.000000\tTranslation_Loss: 0.097804\tTime: 0.02\n",
      "Train Epoch: 21 \tRotation_Loss: 16586846.000000\tTranslation_Loss: 0.097533\tTime: 0.02\n",
      "Train Epoch: 22 \tRotation_Loss: 15759289.000000\tTranslation_Loss: 0.097336\tTime: 0.02\n",
      "Train Epoch: 23 \tRotation_Loss: 14879063.000000\tTranslation_Loss: 0.097208\tTime: 0.02\n",
      "Train Epoch: 24 \tRotation_Loss: 13963963.000000\tTranslation_Loss: 0.097143\tTime: 0.02\n",
      "Train Epoch: 25 \tRotation_Loss: 13029957.000000\tTranslation_Loss: 0.097136\tTime: 0.02\n",
      "Train Epoch: 26 \tRotation_Loss: 12091144.000000\tTranslation_Loss: 0.097181\tTime: 0.02\n",
      "Train Epoch: 27 \tRotation_Loss: 11159749.000000\tTranslation_Loss: 0.097271\tTime: 0.02\n",
      "Train Epoch: 28 \tRotation_Loss: 10246189.000000\tTranslation_Loss: 0.097402\tTime: 0.02\n",
      "Train Epoch: 29 \tRotation_Loss: 9359147.000000\tTranslation_Loss: 0.097567\tTime: 0.02\n",
      "Train Epoch: 30 \tRotation_Loss: 8505680.000000\tTranslation_Loss: 0.097761\tTime: 0.02\n",
      "Train Epoch: 31 \tRotation_Loss: 7691339.500000\tTranslation_Loss: 0.097978\tTime: 0.02\n",
      "Train Epoch: 32 \tRotation_Loss: 6920307.500000\tTranslation_Loss: 0.098213\tTime: 0.02\n",
      "Train Epoch: 33 \tRotation_Loss: 6195534.500000\tTranslation_Loss: 0.098463\tTime: 0.02\n",
      "Train Epoch: 34 \tRotation_Loss: 5518874.000000\tTranslation_Loss: 0.098722\tTime: 0.02\n",
      "Train Epoch: 35 \tRotation_Loss: 4891227.500000\tTranslation_Loss: 0.098988\tTime: 0.02\n",
      "Train Epoch: 36 \tRotation_Loss: 4312675.500000\tTranslation_Loss: 0.099255\tTime: 0.02\n",
      "Train Epoch: 37 \tRotation_Loss: 3782603.500000\tTranslation_Loss: 0.099522\tTime: 0.02\n",
      "Train Epoch: 38 \tRotation_Loss: 3299817.750000\tTranslation_Loss: 0.099786\tTime: 0.02\n",
      "Train Epoch: 39 \tRotation_Loss: 2862661.250000\tTranslation_Loss: 0.100044\tTime: 0.02\n",
      "Train Epoch: 40 \tRotation_Loss: 2469107.750000\tTranslation_Loss: 0.100294\tTime: 0.02\n",
      "Train Epoch: 41 \tRotation_Loss: 2116854.500000\tTranslation_Loss: 0.100535\tTime: 0.02\n",
      "Train Epoch: 42 \tRotation_Loss: 1803400.500000\tTranslation_Loss: 0.100766\tTime: 0.02\n",
      "Train Epoch: 43 \tRotation_Loss: 1526118.250000\tTranslation_Loss: 0.100984\tTime: 0.02\n",
      "Train Epoch: 44 \tRotation_Loss: 1282312.875000\tTranslation_Loss: 0.101190\tTime: 0.02\n",
      "Train Epoch: 45 \tRotation_Loss: 1069275.250000\tTranslation_Loss: 0.101383\tTime: 0.02\n",
      "Train Epoch: 46 \tRotation_Loss: 884324.312500\tTranslation_Loss: 0.101562\tTime: 0.02\n",
      "Train Epoch: 47 \tRotation_Loss: 724843.312500\tTranslation_Loss: 0.101728\tTime: 0.02\n",
      "Train Epoch: 48 \tRotation_Loss: 588308.375000\tTranslation_Loss: 0.101880\tTime: 0.02\n",
      "Train Epoch: 49 \tRotation_Loss: 472310.937500\tTranslation_Loss: 0.102018\tTime: 0.02\n",
      "Train Epoch: 50 \tRotation_Loss: 374574.156250\tTranslation_Loss: 0.102143\tTime: 0.02\n",
      "Train Epoch: 51 \tRotation_Loss: 292965.125000\tTranslation_Loss: 0.102254\tTime: 0.02\n",
      "Train Epoch: 52 \tRotation_Loss: 225501.796875\tTranslation_Loss: 0.102353\tTime: 0.02\n",
      "Train Epoch: 53 \tRotation_Loss: 170357.031250\tTranslation_Loss: 0.102440\tTime: 0.02\n",
      "Train Epoch: 54 \tRotation_Loss: 125859.101562\tTranslation_Loss: 0.102515\tTime: 0.02\n",
      "Train Epoch: 55 \tRotation_Loss: 90489.625000\tTranslation_Loss: 0.102580\tTime: 0.02\n",
      "Train Epoch: 56 \tRotation_Loss: 62879.570312\tTranslation_Loss: 0.102634\tTime: 0.02\n",
      "Train Epoch: 57 \tRotation_Loss: 41803.332031\tTranslation_Loss: 0.102678\tTime: 0.02\n",
      "Train Epoch: 58 \tRotation_Loss: 26171.775391\tTranslation_Loss: 0.102713\tTime: 0.02\n",
      "Train Epoch: 59 \tRotation_Loss: 15024.176758\tTranslation_Loss: 0.102740\tTime: 0.02\n",
      "Train Epoch: 60 \tRotation_Loss: 7519.592285\tTranslation_Loss: 0.102759\tTime: 0.02\n",
      "Train Epoch: 61 \tRotation_Loss: 2927.712402\tTranslation_Loss: 0.102771\tTime: 0.02\n",
      "Train Epoch: 62 \tRotation_Loss: 618.892883\tTranslation_Loss: 0.102777\tTime: 0.02\n",
      "Train Epoch: 63 \tRotation_Loss: 51.419941\tTranslation_Loss: 0.102777\tTime: 0.02\n",
      "Train Epoch: 64 \tRotation_Loss: 776.470520\tTranslation_Loss: 0.102771\tTime: 0.02\n",
      "Train Epoch: 65 \tRotation_Loss: 2429.510742\tTranslation_Loss: 0.102761\tTime: 0.02\n",
      "Train Epoch: 66 \tRotation_Loss: 4702.244141\tTranslation_Loss: 0.102747\tTime: 0.02\n",
      "Train Epoch: 67 \tRotation_Loss: 7358.674316\tTranslation_Loss: 0.102730\tTime: 0.02\n",
      "Train Epoch: 68 \tRotation_Loss: 10205.841797\tTranslation_Loss: 0.102709\tTime: 0.02\n",
      "Train Epoch: 69 \tRotation_Loss: 13069.051758\tTranslation_Loss: 0.102685\tTime: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 70 \tRotation_Loss: 15815.524414\tTranslation_Loss: 0.102659\tTime: 0.02\n",
      "Train Epoch: 71 \tRotation_Loss: 18348.115234\tTranslation_Loss: 0.102631\tTime: 0.02\n",
      "Train Epoch: 72 \tRotation_Loss: 20599.269531\tTranslation_Loss: 0.102601\tTime: 0.02\n",
      "Train Epoch: 73 \tRotation_Loss: 22525.765625\tTranslation_Loss: 0.102570\tTime: 0.02\n",
      "Train Epoch: 74 \tRotation_Loss: 24104.119141\tTranslation_Loss: 0.102538\tTime: 0.02\n",
      "Train Epoch: 75 \tRotation_Loss: 25326.699219\tTranslation_Loss: 0.102506\tTime: 0.02\n",
      "Train Epoch: 76 \tRotation_Loss: 26198.371094\tTranslation_Loss: 0.102473\tTime: 0.02\n",
      "Train Epoch: 77 \tRotation_Loss: 26733.603516\tTranslation_Loss: 0.102439\tTime: 0.02\n",
      "Train Epoch: 78 \tRotation_Loss: 26953.996094\tTranslation_Loss: 0.102406\tTime: 0.02\n",
      "Train Epoch: 79 \tRotation_Loss: 26886.181641\tTranslation_Loss: 0.102373\tTime: 0.02\n",
      "Train Epoch: 80 \tRotation_Loss: 26560.058594\tTranslation_Loss: 0.102340\tTime: 0.02\n",
      "Train Epoch: 81 \tRotation_Loss: 26007.316406\tTranslation_Loss: 0.102307\tTime: 0.02\n",
      "Train Epoch: 82 \tRotation_Loss: 25260.228516\tTranslation_Loss: 0.102276\tTime: 0.02\n",
      "Train Epoch: 83 \tRotation_Loss: 24350.728516\tTranslation_Loss: 0.102245\tTime: 0.02\n",
      "Train Epoch: 84 \tRotation_Loss: 23309.634766\tTranslation_Loss: 0.102214\tTime: 0.02\n",
      "Train Epoch: 85 \tRotation_Loss: 22166.119141\tTranslation_Loss: 0.102185\tTime: 0.02\n",
      "Train Epoch: 86 \tRotation_Loss: 20947.281250\tTranslation_Loss: 0.102156\tTime: 0.02\n",
      "Train Epoch: 87 \tRotation_Loss: 19677.900391\tTranslation_Loss: 0.102128\tTime: 0.02\n",
      "Train Epoch: 88 \tRotation_Loss: 18380.240234\tTranslation_Loss: 0.102102\tTime: 0.02\n",
      "Train Epoch: 89 \tRotation_Loss: 17074.011719\tTranslation_Loss: 0.102076\tTime: 0.02\n",
      "Train Epoch: 90 \tRotation_Loss: 15776.348633\tTranslation_Loss: 0.102052\tTime: 0.02\n",
      "Train Epoch: 91 \tRotation_Loss: 14501.890625\tTranslation_Loss: 0.102028\tTime: 0.02\n",
      "Train Epoch: 92 \tRotation_Loss: 13262.879883\tTranslation_Loss: 0.102006\tTime: 0.02\n",
      "Train Epoch: 93 \tRotation_Loss: 12069.299805\tTranslation_Loss: 0.101985\tTime: 0.02\n",
      "Train Epoch: 94 \tRotation_Loss: 10929.048828\tTranslation_Loss: 0.101965\tTime: 0.02\n",
      "Train Epoch: 95 \tRotation_Loss: 9848.116211\tTranslation_Loss: 0.101946\tTime: 0.02\n",
      "Train Epoch: 96 \tRotation_Loss: 8830.767578\tTranslation_Loss: 0.101928\tTime: 0.02\n",
      "Train Epoch: 97 \tRotation_Loss: 7879.741211\tTranslation_Loss: 0.101911\tTime: 0.02\n",
      "Train Epoch: 98 \tRotation_Loss: 6996.441895\tTranslation_Loss: 0.101895\tTime: 0.02\n",
      "Train Epoch: 99 \tRotation_Loss: 6181.116699\tTranslation_Loss: 0.101880\tTime: 0.02\n",
      "Train Epoch: 100 \tRotation_Loss: 5433.038086\tTranslation_Loss: 0.101866\tTime: 0.02\n",
      "Train Epoch: 101 \tRotation_Loss: 4750.664551\tTranslation_Loss: 0.101853\tTime: 0.02\n",
      "Train Epoch: 102 \tRotation_Loss: 4131.785645\tTranslation_Loss: 0.101841\tTime: 0.02\n",
      "Train Epoch: 103 \tRotation_Loss: 3573.671143\tTranslation_Loss: 0.101829\tTime: 0.02\n",
      "Train Epoch: 104 \tRotation_Loss: 3073.189941\tTranslation_Loss: 0.101819\tTime: 0.02\n",
      "Train Epoch: 105 \tRotation_Loss: 2626.924805\tTranslation_Loss: 0.101809\tTime: 0.02\n",
      "Train Epoch: 106 \tRotation_Loss: 2231.270020\tTranslation_Loss: 0.101801\tTime: 0.02\n",
      "Train Epoch: 107 \tRotation_Loss: 1882.515381\tTranslation_Loss: 0.101792\tTime: 0.02\n",
      "Train Epoch: 108 \tRotation_Loss: 1576.919678\tTranslation_Loss: 0.101785\tTime: 0.02\n",
      "Train Epoch: 109 \tRotation_Loss: 1310.777832\tTranslation_Loss: 0.101778\tTime: 0.02\n",
      "Train Epoch: 110 \tRotation_Loss: 1080.475220\tTranslation_Loss: 0.101772\tTime: 0.02\n",
      "Train Epoch: 111 \tRotation_Loss: 882.534973\tTranslation_Loss: 0.101767\tTime: 0.02\n",
      "Train Epoch: 112 \tRotation_Loss: 713.654236\tTranslation_Loss: 0.101762\tTime: 0.02\n",
      "Train Epoch: 113 \tRotation_Loss: 570.723755\tTranslation_Loss: 0.101758\tTime: 0.02\n",
      "Train Epoch: 114 \tRotation_Loss: 450.837341\tTranslation_Loss: 0.101754\tTime: 0.02\n",
      "Train Epoch: 115 \tRotation_Loss: 351.285797\tTranslation_Loss: 0.101750\tTime: 0.02\n",
      "Train Epoch: 116 \tRotation_Loss: 269.548645\tTranslation_Loss: 0.101747\tTime: 0.02\n",
      "Train Epoch: 117 \tRotation_Loss: 203.274689\tTranslation_Loss: 0.101745\tTime: 0.02\n",
      "Train Epoch: 118 \tRotation_Loss: 150.273621\tTranslation_Loss: 0.101743\tTime: 0.02\n",
      "Train Epoch: 119 \tRotation_Loss: 108.531456\tTranslation_Loss: 0.101741\tTime: 0.02\n",
      "Train Epoch: 120 \tRotation_Loss: 76.248932\tTranslation_Loss: 0.101739\tTime: 0.02\n",
      "Train Epoch: 121 \tRotation_Loss: 51.893276\tTranslation_Loss: 0.101738\tTime: 0.02\n",
      "Train Epoch: 122 \tRotation_Loss: 34.124649\tTranslation_Loss: 0.101737\tTime: 0.02\n",
      "Train Epoch: 123 \tRotation_Loss: 21.755890\tTranslation_Loss: 0.101737\tTime: 0.02\n",
      "Train Epoch: 124 \tRotation_Loss: 13.855462\tTranslation_Loss: 0.101736\tTime: 0.02\n",
      "Train Epoch: 125 \tRotation_Loss: 9.796987\tTranslation_Loss: 0.101736\tTime: 0.02\n",
      "Train Epoch: 126 \tRotation_Loss: 7.924857\tTranslation_Loss: 0.101736\tTime: 0.02\n",
      "Train Epoch: 127 \tRotation_Loss: 7.613897\tTranslation_Loss: 0.101736\tTime: 0.02\n",
      "Train Epoch: 128 \tRotation_Loss: 8.536103\tTranslation_Loss: 0.101737\tTime: 0.02\n",
      "Train Epoch: 129 \tRotation_Loss: 10.571603\tTranslation_Loss: 0.101737\tTime: 0.02\n",
      "Train Epoch: 130 \tRotation_Loss: 13.333753\tTranslation_Loss: 0.101738\tTime: 0.02\n",
      "Train Epoch: 131 \tRotation_Loss: 16.808325\tTranslation_Loss: 0.101738\tTime: 0.02\n",
      "Train Epoch: 132 \tRotation_Loss: 20.785030\tTranslation_Loss: 0.101739\tTime: 0.02\n",
      "Train Epoch: 133 \tRotation_Loss: 24.960546\tTranslation_Loss: 0.101740\tTime: 0.02\n",
      "Train Epoch: 134 \tRotation_Loss: 29.061419\tTranslation_Loss: 0.101741\tTime: 0.02\n",
      "Train Epoch: 135 \tRotation_Loss: 32.961670\tTranslation_Loss: 0.101742\tTime: 0.02\n",
      "Train Epoch: 136 \tRotation_Loss: 36.530872\tTranslation_Loss: 0.101743\tTime: 0.02\n",
      "Train Epoch: 137 \tRotation_Loss: 39.665730\tTranslation_Loss: 0.101744\tTime: 0.02\n",
      "Train Epoch: 138 \tRotation_Loss: 42.327141\tTranslation_Loss: 0.101745\tTime: 0.02\n",
      "Train Epoch: 139 \tRotation_Loss: 44.505276\tTranslation_Loss: 0.101746\tTime: 0.02\n",
      "Train Epoch: 140 \tRotation_Loss: 46.176491\tTranslation_Loss: 0.101747\tTime: 0.02\n",
      "Train Epoch: 141 \tRotation_Loss: 47.342667\tTranslation_Loss: 0.101748\tTime: 0.02\n",
      "Train Epoch: 142 \tRotation_Loss: 48.042225\tTranslation_Loss: 0.101749\tTime: 0.02\n",
      "Train Epoch: 143 \tRotation_Loss: 48.317024\tTranslation_Loss: 0.101750\tTime: 0.02\n",
      "Train Epoch: 144 \tRotation_Loss: 48.192509\tTranslation_Loss: 0.101752\tTime: 0.02\n",
      "Train Epoch: 145 \tRotation_Loss: 47.685535\tTranslation_Loss: 0.101753\tTime: 0.02\n",
      "Train Epoch: 146 \tRotation_Loss: 46.822586\tTranslation_Loss: 0.101754\tTime: 0.02\n",
      "Train Epoch: 147 \tRotation_Loss: 45.647579\tTranslation_Loss: 0.101755\tTime: 0.02\n",
      "Train Epoch: 148 \tRotation_Loss: 44.214882\tTranslation_Loss: 0.101756\tTime: 0.02\n",
      "Train Epoch: 149 \tRotation_Loss: 42.576286\tTranslation_Loss: 0.101757\tTime: 0.02\n",
      "Train Epoch: 150 \tRotation_Loss: 40.771416\tTranslation_Loss: 0.101758\tTime: 0.02\n",
      "Train Epoch: 151 \tRotation_Loss: 38.841663\tTranslation_Loss: 0.101759\tTime: 0.02\n",
      "Train Epoch: 152 \tRotation_Loss: 36.824139\tTranslation_Loss: 0.101760\tTime: 0.02\n",
      "Train Epoch: 153 \tRotation_Loss: 34.745682\tTranslation_Loss: 0.101760\tTime: 0.02\n",
      "Train Epoch: 154 \tRotation_Loss: 32.619934\tTranslation_Loss: 0.101761\tTime: 0.02\n",
      "Train Epoch: 155 \tRotation_Loss: 30.467337\tTranslation_Loss: 0.101762\tTime: 0.02\n",
      "Train Epoch: 156 \tRotation_Loss: 28.321024\tTranslation_Loss: 0.101763\tTime: 0.02\n",
      "Train Epoch: 157 \tRotation_Loss: 26.216532\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 158 \tRotation_Loss: 24.181902\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 159 \tRotation_Loss: 22.235640\tTranslation_Loss: 0.101765\tTime: 0.02\n",
      "Train Epoch: 160 \tRotation_Loss: 20.383707\tTranslation_Loss: 0.101766\tTime: 0.02\n",
      "Train Epoch: 161 \tRotation_Loss: 18.621590\tTranslation_Loss: 0.101766\tTime: 0.02\n",
      "Train Epoch: 162 \tRotation_Loss: 16.943464\tTranslation_Loss: 0.101767\tTime: 0.02\n",
      "Train Epoch: 163 \tRotation_Loss: 15.354124\tTranslation_Loss: 0.101767\tTime: 0.02\n",
      "Train Epoch: 164 \tRotation_Loss: 13.863970\tTranslation_Loss: 0.101768\tTime: 0.02\n",
      "Train Epoch: 165 \tRotation_Loss: 12.479108\tTranslation_Loss: 0.101768\tTime: 0.02\n",
      "Train Epoch: 166 \tRotation_Loss: 11.199224\tTranslation_Loss: 0.101768\tTime: 0.02\n",
      "Train Epoch: 167 \tRotation_Loss: 10.015264\tTranslation_Loss: 0.101769\tTime: 0.02\n",
      "Train Epoch: 168 \tRotation_Loss: 8.922948\tTranslation_Loss: 0.101769\tTime: 0.02\n",
      "Train Epoch: 169 \tRotation_Loss: 7.929273\tTranslation_Loss: 0.101769\tTime: 0.02\n",
      "Train Epoch: 170 \tRotation_Loss: 7.054980\tTranslation_Loss: 0.101769\tTime: 0.02\n",
      "Train Epoch: 171 \tRotation_Loss: 6.261983\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 172 \tRotation_Loss: 5.541007\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 173 \tRotation_Loss: 5.032755\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 174 \tRotation_Loss: 4.676674\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 175 \tRotation_Loss: 4.519876\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 176 \tRotation_Loss: 4.558224\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 177 \tRotation_Loss: 4.718991\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 178 \tRotation_Loss: 52.193165\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 179 \tRotation_Loss: 369.784607\tTranslation_Loss: 0.101772\tTime: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 180 \tRotation_Loss: 1074.671875\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 181 \tRotation_Loss: 2054.594238\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 182 \tRotation_Loss: 3197.641846\tTranslation_Loss: 0.101769\tTime: 0.02\n",
      "Train Epoch: 183 \tRotation_Loss: 4415.334473\tTranslation_Loss: 0.101768\tTime: 0.02\n",
      "Train Epoch: 184 \tRotation_Loss: 5640.160156\tTranslation_Loss: 0.101767\tTime: 0.02\n",
      "Train Epoch: 185 \tRotation_Loss: 6818.159668\tTranslation_Loss: 0.101767\tTime: 0.02\n",
      "Train Epoch: 186 \tRotation_Loss: 7908.227539\tTranslation_Loss: 0.101766\tTime: 0.02\n",
      "Train Epoch: 187 \tRotation_Loss: 8881.011719\tTranslation_Loss: 0.101766\tTime: 0.02\n",
      "Train Epoch: 188 \tRotation_Loss: 9717.230469\tTranslation_Loss: 0.101765\tTime: 0.02\n",
      "Train Epoch: 189 \tRotation_Loss: 10405.958008\tTranslation_Loss: 0.101765\tTime: 0.02\n",
      "Train Epoch: 190 \tRotation_Loss: 10943.080078\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 191 \tRotation_Loss: 11329.935547\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 192 \tRotation_Loss: 11572.123047\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 193 \tRotation_Loss: 11678.429688\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 194 \tRotation_Loss: 11659.925781\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 195 \tRotation_Loss: 11529.173828\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 196 \tRotation_Loss: 11299.599609\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 197 \tRotation_Loss: 10984.973633\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 198 \tRotation_Loss: 10598.971680\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 199 \tRotation_Loss: 10154.864258\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 200 \tRotation_Loss: 9665.252930\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 201 \tRotation_Loss: 9141.886719\tTranslation_Loss: 0.101764\tTime: 0.02\n",
      "Train Epoch: 202 \tRotation_Loss: 8595.534180\tTranslation_Loss: 0.101765\tTime: 0.02\n",
      "Train Epoch: 203 \tRotation_Loss: 8035.907227\tTranslation_Loss: 0.101765\tTime: 0.02\n",
      "Train Epoch: 204 \tRotation_Loss: 7471.623535\tTranslation_Loss: 0.101765\tTime: 0.02\n",
      "Train Epoch: 205 \tRotation_Loss: 6910.196777\tTranslation_Loss: 0.101765\tTime: 0.02\n",
      "Train Epoch: 206 \tRotation_Loss: 6358.063477\tTranslation_Loss: 0.101765\tTime: 0.02\n",
      "Train Epoch: 207 \tRotation_Loss: 5820.625977\tTranslation_Loss: 0.101766\tTime: 0.02\n",
      "Train Epoch: 208 \tRotation_Loss: 5302.310547\tTranslation_Loss: 0.101766\tTime: 0.02\n",
      "Train Epoch: 209 \tRotation_Loss: 4806.633789\tTranslation_Loss: 0.101766\tTime: 0.02\n",
      "Train Epoch: 210 \tRotation_Loss: 4336.279785\tTranslation_Loss: 0.101766\tTime: 0.02\n",
      "Train Epoch: 211 \tRotation_Loss: 3893.181396\tTranslation_Loss: 0.101767\tTime: 0.02\n",
      "Train Epoch: 212 \tRotation_Loss: 3478.607666\tTranslation_Loss: 0.101767\tTime: 0.02\n",
      "Train Epoch: 213 \tRotation_Loss: 3093.237549\tTranslation_Loss: 0.101767\tTime: 0.02\n",
      "Train Epoch: 214 \tRotation_Loss: 2737.240723\tTranslation_Loss: 0.101767\tTime: 0.02\n",
      "Train Epoch: 215 \tRotation_Loss: 2410.353271\tTranslation_Loss: 0.101767\tTime: 0.02\n",
      "Train Epoch: 216 \tRotation_Loss: 2111.950928\tTranslation_Loss: 0.101768\tTime: 0.02\n",
      "Train Epoch: 217 \tRotation_Loss: 1841.113770\tTranslation_Loss: 0.101768\tTime: 0.02\n",
      "Train Epoch: 218 \tRotation_Loss: 1596.685791\tTranslation_Loss: 0.101768\tTime: 0.02\n",
      "Train Epoch: 219 \tRotation_Loss: 1377.334961\tTranslation_Loss: 0.101768\tTime: 0.02\n",
      "Train Epoch: 220 \tRotation_Loss: 1181.601196\tTranslation_Loss: 0.101768\tTime: 0.02\n",
      "Train Epoch: 221 \tRotation_Loss: 1007.932739\tTranslation_Loss: 0.101769\tTime: 0.02\n",
      "Train Epoch: 222 \tRotation_Loss: 854.721497\tTranslation_Loss: 0.101769\tTime: 0.02\n",
      "Train Epoch: 223 \tRotation_Loss: 720.332825\tTranslation_Loss: 0.101769\tTime: 0.02\n",
      "Train Epoch: 224 \tRotation_Loss: 603.137146\tTranslation_Loss: 0.101769\tTime: 0.02\n",
      "Train Epoch: 225 \tRotation_Loss: 501.540924\tTranslation_Loss: 0.101769\tTime: 0.02\n",
      "Train Epoch: 226 \tRotation_Loss: 414.025696\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 227 \tRotation_Loss: 339.164368\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 228 \tRotation_Loss: 275.621918\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 229 \tRotation_Loss: 222.143417\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 230 \tRotation_Loss: 177.539703\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 231 \tRotation_Loss: 140.687332\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 232 \tRotation_Loss: 110.535065\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 233 \tRotation_Loss: 86.150879\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 234 \tRotation_Loss: 66.685760\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 235 \tRotation_Loss: 51.404438\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 236 \tRotation_Loss: 39.667770\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 237 \tRotation_Loss: 30.804270\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 238 \tRotation_Loss: 24.069555\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 239 \tRotation_Loss: 20.069941\tTranslation_Loss: 0.101770\tTime: 0.02\n",
      "Train Epoch: 240 \tRotation_Loss: 18.451931\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 241 \tRotation_Loss: 18.897808\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 242 \tRotation_Loss: 21.042778\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 243 \tRotation_Loss: 24.529644\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 244 \tRotation_Loss: 28.778131\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 245 \tRotation_Loss: 33.337486\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 246 \tRotation_Loss: 38.014423\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 247 \tRotation_Loss: 42.669323\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 248 \tRotation_Loss: 47.105820\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 249 \tRotation_Loss: 51.142918\tTranslation_Loss: 0.101771\tTime: 0.02\n",
      "Train Epoch: 1 \tRotation_Loss: 3378.738770\tTranslation_Loss: 0.197788\tTime: 0.02\n",
      "Train Epoch: 2 \tRotation_Loss: 12077.911133\tTranslation_Loss: 0.195184\tTime: 0.02\n",
      "Train Epoch: 3 \tRotation_Loss: 24320.484375\tTranslation_Loss: 0.191565\tTime: 0.02\n",
      "Train Epoch: 4 \tRotation_Loss: 38659.175781\tTranslation_Loss: 0.187120\tTime: 0.02\n",
      "Train Epoch: 5 \tRotation_Loss: 53935.953125\tTranslation_Loss: 0.182034\tTime: 0.02\n",
      "Train Epoch: 6 \tRotation_Loss: 69243.695312\tTranslation_Loss: 0.176485\tTime: 0.02\n",
      "Train Epoch: 7 \tRotation_Loss: 83890.867188\tTranslation_Loss: 0.170635\tTime: 0.02\n",
      "Train Epoch: 8 \tRotation_Loss: 97369.335938\tTranslation_Loss: 0.164635\tTime: 0.02\n",
      "Train Epoch: 9 \tRotation_Loss: 109325.179688\tTranslation_Loss: 0.158619\tTime: 0.02\n",
      "Train Epoch: 10 \tRotation_Loss: 119532.625000\tTranslation_Loss: 0.152703\tTime: 0.02\n",
      "Train Epoch: 11 \tRotation_Loss: 127870.750000\tTranslation_Loss: 0.146986\tTime: 0.02\n",
      "Train Epoch: 12 \tRotation_Loss: 134303.015625\tTranslation_Loss: 0.141551\tTime: 0.02\n",
      "Train Epoch: 13 \tRotation_Loss: 138859.265625\tTranslation_Loss: 0.136463\tTime: 0.02\n",
      "Train Epoch: 14 \tRotation_Loss: 141620.328125\tTranslation_Loss: 0.131774\tTime: 0.02\n",
      "Train Epoch: 15 \tRotation_Loss: 142704.625000\tTranslation_Loss: 0.127519\tTime: 0.02\n",
      "Train Epoch: 16 \tRotation_Loss: 142256.843750\tTranslation_Loss: 0.123725\tTime: 0.02\n",
      "Train Epoch: 17 \tRotation_Loss: 140438.640625\tTranslation_Loss: 0.120402\tTime: 0.02\n",
      "Train Epoch: 18 \tRotation_Loss: 137420.640625\tTranslation_Loss: 0.117553\tTime: 0.02\n",
      "Train Epoch: 19 \tRotation_Loss: 133376.328125\tTranslation_Loss: 0.115173\tTime: 0.02\n",
      "Train Epoch: 20 \tRotation_Loss: 128476.789062\tTranslation_Loss: 0.113248\tTime: 0.02\n",
      "Train Epoch: 21 \tRotation_Loss: 122886.945312\tTranslation_Loss: 0.111758\tTime: 0.02\n",
      "Train Epoch: 22 \tRotation_Loss: 116762.484375\tTranslation_Loss: 0.110681\tTime: 0.02\n",
      "Train Epoch: 23 \tRotation_Loss: 110247.789062\tTranslation_Loss: 0.109988\tTime: 0.02\n",
      "Train Epoch: 24 \tRotation_Loss: 103474.593750\tTranslation_Loss: 0.109649\tTime: 0.02\n",
      "Train Epoch: 25 \tRotation_Loss: 96561.054688\tTranslation_Loss: 0.109632\tTime: 0.02\n",
      "Train Epoch: 26 \tRotation_Loss: 89611.562500\tTranslation_Loss: 0.109904\tTime: 0.02\n",
      "Train Epoch: 27 \tRotation_Loss: 82716.609375\tTranslation_Loss: 0.110431\tTime: 0.02\n",
      "Train Epoch: 28 \tRotation_Loss: 75953.335938\tTranslation_Loss: 0.111181\tTime: 0.02\n",
      "Train Epoch: 29 \tRotation_Loss: 69386.007812\tTranslation_Loss: 0.112122\tTime: 0.02\n",
      "Train Epoch: 30 \tRotation_Loss: 63066.902344\tTranslation_Loss: 0.113221\tTime: 0.02\n",
      "Train Epoch: 31 \tRotation_Loss: 57037.140625\tTranslation_Loss: 0.114451\tTime: 0.02\n",
      "Train Epoch: 32 \tRotation_Loss: 51327.675781\tTranslation_Loss: 0.115783\tTime: 0.02\n",
      "Train Epoch: 33 \tRotation_Loss: 45960.335938\tTranslation_Loss: 0.117192\tTime: 0.02\n",
      "Train Epoch: 34 \tRotation_Loss: 40948.898438\tTranslation_Loss: 0.118654\tTime: 0.02\n",
      "Train Epoch: 35 \tRotation_Loss: 36300.039062\tTranslation_Loss: 0.120147\tTime: 0.02\n",
      "Train Epoch: 36 \tRotation_Loss: 32014.365234\tTranslation_Loss: 0.121653\tTime: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 \tRotation_Loss: 28087.378906\tTranslation_Loss: 0.123153\tTime: 0.02\n",
      "Train Epoch: 38 \tRotation_Loss: 24510.291016\tTranslation_Loss: 0.124634\tTime: 0.02\n",
      "Train Epoch: 39 \tRotation_Loss: 21270.873047\tTranslation_Loss: 0.126082\tTime: 0.02\n",
      "Train Epoch: 40 \tRotation_Loss: 18354.183594\tTranslation_Loss: 0.127486\tTime: 0.02\n",
      "Train Epoch: 41 \tRotation_Loss: 15743.200195\tTranslation_Loss: 0.128836\tTime: 0.02\n",
      "Train Epoch: 42 \tRotation_Loss: 13419.388672\tTranslation_Loss: 0.130125\tTime: 0.02\n",
      "Train Epoch: 43 \tRotation_Loss: 11363.314453\tTranslation_Loss: 0.131348\tTime: 0.02\n",
      "Train Epoch: 44 \tRotation_Loss: 9555.061523\tTranslation_Loss: 0.132499\tTime: 0.02\n",
      "Train Epoch: 45 \tRotation_Loss: 7974.543457\tTranslation_Loss: 0.133576\tTime: 0.02\n",
      "Train Epoch: 46 \tRotation_Loss: 6601.802734\tTranslation_Loss: 0.134576\tTime: 0.02\n",
      "Train Epoch: 47 \tRotation_Loss: 5417.520508\tTranslation_Loss: 0.135498\tTime: 0.02\n",
      "Train Epoch: 48 \tRotation_Loss: 4403.165039\tTranslation_Loss: 0.136343\tTime: 0.02\n",
      "Train Epoch: 49 \tRotation_Loss: 3540.960205\tTranslation_Loss: 0.137111\tTime: 0.02\n",
      "Train Epoch: 50 \tRotation_Loss: 2814.094482\tTranslation_Loss: 0.137803\tTime: 0.02\n",
      "Train Epoch: 51 \tRotation_Loss: 2206.574463\tTranslation_Loss: 0.138421\tTime: 0.02\n",
      "Train Epoch: 52 \tRotation_Loss: 1703.916260\tTranslation_Loss: 0.138969\tTime: 0.02\n",
      "Train Epoch: 53 \tRotation_Loss: 1292.711426\tTranslation_Loss: 0.139448\tTime: 0.02\n",
      "Train Epoch: 54 \tRotation_Loss: 960.677856\tTranslation_Loss: 0.139863\tTime: 0.02\n",
      "Train Epoch: 55 \tRotation_Loss: 698.239319\tTranslation_Loss: 0.140215\tTime: 0.02\n",
      "Train Epoch: 56 \tRotation_Loss: 494.394318\tTranslation_Loss: 0.140510\tTime: 0.02\n",
      "Train Epoch: 57 \tRotation_Loss: 340.718384\tTranslation_Loss: 0.140750\tTime: 0.02\n",
      "Train Epoch: 58 \tRotation_Loss: 256.187866\tTranslation_Loss: 0.140940\tTime: 0.02\n",
      "Train Epoch: 59 \tRotation_Loss: 266.164917\tTranslation_Loss: 0.141082\tTime: 0.02\n",
      "Train Epoch: 60 \tRotation_Loss: 374.536316\tTranslation_Loss: 0.141182\tTime: 0.02\n",
      "Train Epoch: 61 \tRotation_Loss: 568.941528\tTranslation_Loss: 0.141243\tTime: 0.02\n",
      "Train Epoch: 62 \tRotation_Loss: 852.308716\tTranslation_Loss: 0.141269\tTime: 0.02\n",
      "Train Epoch: 63 \tRotation_Loss: 1223.475952\tTranslation_Loss: 0.141261\tTime: 0.02\n",
      "Train Epoch: 64 \tRotation_Loss: 1640.053589\tTranslation_Loss: 0.141224\tTime: 0.02\n",
      "Train Epoch: 65 \tRotation_Loss: 2061.407471\tTranslation_Loss: 0.141160\tTime: 0.02\n",
      "Train Epoch: 66 \tRotation_Loss: 2478.485596\tTranslation_Loss: 0.141073\tTime: 0.02\n",
      "Train Epoch: 67 \tRotation_Loss: 2880.061768\tTranslation_Loss: 0.140966\tTime: 0.02\n",
      "Train Epoch: 68 \tRotation_Loss: 3251.020020\tTranslation_Loss: 0.140841\tTime: 0.02\n",
      "Train Epoch: 69 \tRotation_Loss: 3581.979980\tTranslation_Loss: 0.140702\tTime: 0.02\n",
      "Train Epoch: 70 \tRotation_Loss: 3866.304688\tTranslation_Loss: 0.140549\tTime: 0.02\n",
      "Train Epoch: 71 \tRotation_Loss: 4099.834961\tTranslation_Loss: 0.140386\tTime: 0.02\n",
      "Train Epoch: 72 \tRotation_Loss: 4280.486328\tTranslation_Loss: 0.140214\tTime: 0.02\n",
      "Train Epoch: 73 \tRotation_Loss: 4407.593750\tTranslation_Loss: 0.140036\tTime: 0.02\n",
      "Train Epoch: 74 \tRotation_Loss: 4482.797363\tTranslation_Loss: 0.139852\tTime: 0.02\n",
      "Train Epoch: 75 \tRotation_Loss: 4509.483398\tTranslation_Loss: 0.139665\tTime: 0.02\n",
      "Train Epoch: 76 \tRotation_Loss: 4491.713379\tTranslation_Loss: 0.139476\tTime: 0.02\n",
      "Train Epoch: 77 \tRotation_Loss: 4433.978516\tTranslation_Loss: 0.139286\tTime: 0.02\n",
      "Train Epoch: 78 \tRotation_Loss: 4341.131348\tTranslation_Loss: 0.139095\tTime: 0.02\n",
      "Train Epoch: 79 \tRotation_Loss: 4217.828613\tTranslation_Loss: 0.138907\tTime: 0.02\n",
      "Train Epoch: 80 \tRotation_Loss: 4068.680664\tTranslation_Loss: 0.138720\tTime: 0.02\n",
      "Train Epoch: 81 \tRotation_Loss: 3898.718018\tTranslation_Loss: 0.138535\tTime: 0.02\n",
      "Train Epoch: 82 \tRotation_Loss: 3713.114258\tTranslation_Loss: 0.138355\tTime: 0.02\n",
      "Train Epoch: 83 \tRotation_Loss: 3516.853027\tTranslation_Loss: 0.138178\tTime: 0.02\n",
      "Train Epoch: 84 \tRotation_Loss: 3314.663330\tTranslation_Loss: 0.138006\tTime: 0.02\n",
      "Train Epoch: 85 \tRotation_Loss: 3110.064941\tTranslation_Loss: 0.137839\tTime: 0.02\n",
      "Train Epoch: 86 \tRotation_Loss: 2905.627686\tTranslation_Loss: 0.137677\tTime: 0.02\n",
      "Train Epoch: 87 \tRotation_Loss: 2703.700684\tTranslation_Loss: 0.137521\tTime: 0.02\n",
      "Train Epoch: 88 \tRotation_Loss: 2506.452393\tTranslation_Loss: 0.137371\tTime: 0.02\n",
      "Train Epoch: 89 \tRotation_Loss: 2315.085205\tTranslation_Loss: 0.137227\tTime: 0.02\n",
      "Train Epoch: 90 \tRotation_Loss: 2129.985107\tTranslation_Loss: 0.137088\tTime: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-f91b0a6b4d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#adjust_learning_rate(optimizer, epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         r_batch_loss, t_batch_loss = rt_learning(model_eval, device, src_rl, target_rl, rotation_ab_rl, translation_ab_rl, \n\u001b[0m\u001b[1;32m     17\u001b[0m                                          optimizer,criterion,epoch,n_batch=1)\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-143-3f8591e2c5dc>\u001b[0m in \u001b[0;36mrt_learning\u001b[0;34m(model, device, src, target, rotation_ab, translation_ab, optimizer, criterion, epoch, n_batch)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtranslation_ab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslation_ab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-c1a9f5d4ce65>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0memb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/geomloss/samples_loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# Run --------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         values = routines[self.loss][backend](\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/geomloss/sinkhorn_samples.py\u001b[0m in \u001b[0;36msinkhorn_tensorized\u001b[0;34m(, x, , y, p, blur, reach, diameter, scaling, cost, debias, potentials, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mdiameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaling_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     a_x, b_y, a_y, b_x = sinkhorn_loop(\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0msoftmin_tensorized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mlog_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/geomloss/sinkhorn_divergence.py\u001b[0m in \u001b[0;36msinkhorn_loop\u001b[0;34m(softmin, _logs, _logs, C_xxs, C_yys, C_xys, C_yxs, _s, , jumps, kernel_truncation, truncate, cost, extrapolate, debias, last_extrapolation)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mat_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msoftmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_xx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_log\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma_x\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0m\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# OT(,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mbt_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msoftmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_yy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_log\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_y\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0m\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# OT(,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mat_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msoftmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_yx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_log\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_x\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0m\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# OT(,) wrt. a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mbt_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msoftmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_log\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma_y\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0m\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# OT(,) wrt. b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for src_rl, target_rl, rotation_ab_rl, translation_ab_rl, rotation_ba_rl, translation_ba_rl,_,_ in rl_loader:\n",
    "    model_eval = CPEvalNet(base_model.base_net,len(src_rl)).to(device)\n",
    "    \n",
    "    criterion = dummy_loss\n",
    "    lr = 1e+1\n",
    "    momentum=0.9\n",
    "    weight_decay = 5e-4\n",
    "    optimizer = torch.optim.SGD(model_eval.parameters(), lr,\n",
    "                                    momentum=momentum,\n",
    "                                    weight_decay=weight_decay)\n",
    "    best=0\n",
    "    \n",
    "    for epoch in range(1,250):\n",
    "        #adjust_learning_rate(optimizer, epoch)\n",
    "        t1 = datetime.now()\n",
    "        r_batch_loss, t_batch_loss = rt_learning(model_eval, device, src_rl, target_rl, rotation_ab_rl, translation_ab_rl, \n",
    "                                         optimizer,criterion,epoch,n_batch=1)\n",
    "        if epoch%40==0:\n",
    "\n",
    "            print('Train Epoch: {} \\tRotation_Loss: {:.6f}\\tTranslation_Loss: {:.6f}\\tTime: {:.2f}'.format(\n",
    "                epoch, r_batch_loss[-1],t_batch_loss[-1],(datetime.now()-t1).total_seconds()))\n",
    "    print(\"*********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = CPEvalNet(base_model.base_net,len(src_rl)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src_rl.to(device)\n",
    "target = target_rl.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1,emb2 = model_eval.cal_emb(src,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0518, -0.1208, -0.6257,  ..., -0.0921,  0.6426,  0.3896],\n",
       "         [ 0.2355,  0.4974,  0.3281,  ...,  0.2768, -0.1622,  0.3229],\n",
       "         [ 0.6433, -0.4532, -0.0385,  ..., -0.1564,  0.9694,  0.5029]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3587,  0.5572,  0.3573]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval.translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tnet, self).__init__()\n",
    "        self.base_net = nn.Linear(4,5)\n",
    "        for param in self.base_net.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.linear = nn.Linear(5,10)\n",
    "\n",
    "        \n",
    "    def forward(self, x1):\n",
    "        \n",
    "        y = self.base_net(x1)\n",
    "        y = self.linear(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_fix = Tnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(128,4)\n",
    "b = torch.randint(9,(128,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fix = nn.CrossEntropyLoss()\n",
    "lr = 1e-0\n",
    "momentum=0.9\n",
    "weight_decay = 5e-4\n",
    "optimizer = torch.optim.SGD(mdl_fix.parameters(), lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "o = mdl_fix(a)\n",
    "loss = loss_fix(o,b)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3622,  0.4383, -0.0323, -0.3923],\n",
       "        [-0.4348, -0.3971,  0.2977, -0.1876],\n",
       "        [ 0.0916, -0.5000, -0.0444,  0.3572],\n",
       "        [ 0.3948, -0.4296,  0.4550,  0.1864],\n",
       "        [ 0.4938,  0.4447,  0.4731, -0.3320]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_fix.base_net.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2740, -0.3083, -0.1948, -0.2773,  0.2340],\n",
       "        [ 0.3289,  0.2262, -0.1302,  0.2608,  0.3197],\n",
       "        [-0.4101, -0.3186, -0.3246, -0.0478,  0.1414],\n",
       "        [ 0.0234, -0.2619, -0.0990, -0.0118, -0.1745],\n",
       "        [ 0.2538,  0.1531, -0.3491,  0.0481, -0.3088],\n",
       "        [-0.0593, -0.3752, -0.1289,  0.2848,  0.3547],\n",
       "        [ 0.4445,  0.1241, -0.2501, -0.4075, -0.2104],\n",
       "        [-0.0064,  0.3962, -0.0112, -0.4004, -0.0814],\n",
       "        [-0.4317, -0.3341, -0.3595, -0.1399,  0.1505],\n",
       "        [ 0.0969, -0.0780, -0.1750, -0.0828, -0.2956]], requires_grad=True)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_fix.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3622,  0.4383, -0.0323, -0.3923],\n",
       "        [-0.4348, -0.3971,  0.2977, -0.1876],\n",
       "        [ 0.0916, -0.5000, -0.0444,  0.3572],\n",
       "        [ 0.3948, -0.4296,  0.4550,  0.1864],\n",
       "        [ 0.4938,  0.4447,  0.4731, -0.3320]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_fix.base_net.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_fix.base_net.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
