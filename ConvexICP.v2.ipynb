{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "# from data import ModelNet40,download,load_data\n",
    "\n",
    "# from data import ModelNet40Convex,download,load_data\n",
    "from data_convex import ModelNet40Convex,download,load_data\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from geomloss import SamplesLoss\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from torch import jit\n",
    "%matplotlib inline\n",
    "import os\n",
    "from torch.utils.data import Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geomloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_results_exp = []\n",
    "test_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 2 every 30 epochs\"\"\"\n",
    "    lrt = lr * (0.5 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yshao\\Downloads\\VOCtrainval_11-May-2012\\DL\\ICP\\ConvexICP-master\\ConvexICP-master\\data_convex.py:44: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  f = h5py.File(h5_name)\n"
     ]
    }
   ],
   "source": [
    "data = ModelNet40Convex(num_points=2048, partition='train', gaussian_noise=False,\n",
    "                       unseen=False, factor=4)\n",
    "data_test = ModelNet40Convex(num_points=2048, partition='test', gaussian_noise=False,\n",
    "                       unseen=False, factor=4)\n",
    "train_loader = DataLoader(data, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(data_test, batch_size=1, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Original\n",
    "# data = ModelNet40(num_points=2048, partition='train', gaussian_noise=False,\n",
    "#                        unseen=False, factor=4)\n",
    "# data_test = ModelNet40(num_points=2048, partition='test', gaussian_noise=False,\n",
    "#                        unseen=False, factor=4)\n",
    "# train_loader = DataLoader(data, batch_size=128, shuffle=True, drop_last=True)\n",
    "# test_loader = DataLoader(data_test, batch_size=1, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loader\n",
      "origina (2048, 3) (3, 2048)\n",
      "origina (2048, 3) (3, 2048)\n",
      "origina (2048, 3) (3, 2048)\n",
      "origina (2048, 3) (3, 2048)\n",
      "0 (2048, 3)\n",
      "1 (3, 2048)\n",
      "2 (3, 2048)\n",
      "3 (3, 2048)\n",
      "4 2\n",
      "5 2\n",
      "6 2\n",
      "7 2\n"
     ]
    }
   ],
   "source": [
    "print('Test Loader')\n",
    "sample=data[0]\n",
    "\n",
    "len(sample)\n",
    "for i,e in enumerate(sample):\n",
    "    try:\n",
    "        print(i,e.shape)\n",
    "    except:\n",
    "        print(i,len(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_icp(model,device, train_loader,test_loader, optimizer,criterion, epoch, eval_mode='on'):\n",
    "    global best\n",
    "    model.train()\n",
    "    final_cal = nn.Sigmoid()\n",
    "    train_error_logs = []\n",
    "    t1 = datetime.now()\n",
    "    test_loss_log = []\n",
    "    test_acc_log = []\n",
    "    train_corrects = 0\n",
    "    \n",
    "    for batch_idx, (src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba) in enumerate(train_loader):\n",
    "        src = src.to(device)\n",
    "        target = target.to(device)\n",
    "        rotation_ab = rotation_ab.to(device)\n",
    "        translation_ab = translation_ab.to(device)\n",
    "        rotation_ba = rotation_ba.to(device)\n",
    "        translation_ba = translation_ba.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_train = model(src,target,rotation_ab,translation_ab)\n",
    "        loss = criterion(output_train, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #pred_train = output_train.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        #train_corrects += pred_train.eq(target.view_as(pred_train)).sum().item()\n",
    "        train_error_logs.append(loss.item())\n",
    "        \n",
    "        if (batch_idx+0) % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime: {:.2f}'.format(\n",
    "                epoch, (batch_idx+0)* len(target), len(train_loader.dataset),\n",
    "                100. * (batch_idx+0) / len(train_loader), loss,(datetime.now()-t1).total_seconds()))\n",
    "\n",
    "        \n",
    "    print('Train Epoch: {} Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "                epoch, train_corrects, len(train_loader.dataset),\n",
    "                100. * train_corrects / len(train_loader.dataset)))\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba in enumerate(test_loader):\n",
    "            src = src.to(device)\n",
    "            target = target.to(device)\n",
    "            rotation_ab = rotation_ab.to(device)\n",
    "            translation_ab = translation_ab.to(device)\n",
    "            rotation_ba = rotation_ba.to(device)\n",
    "            translation_ba = translation_ba.to(device)\n",
    "            output_test = model(src,target,rotation_ab,translation_ab)\n",
    "            test_loss += criterion(output_test, target_test).item()  # sum up batch loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_loss_log.append(test_loss)\n",
    "    print('Test set: Average loss: {:.8f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss, correct_test, len(test_loader.dataset),\n",
    "            100. * correct_test / len(test_loader.dataset)))\n",
    "    return train_error_logs,test_loss_log,test_acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet(nn.Module):\n",
    "    def __init__(self, emb_dims=512):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n",
    "        self.conv3 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n",
    "        self.conv4 = nn.Conv1d(64, 128, kernel_size=1, bias=False)\n",
    "        self.conv5 = nn.Conv1d(128, emb_dims, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.bn5 = nn.BatchNorm1d(emb_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPNet(nn.Module):\n",
    "    def __init__(self, emb_dims=512):\n",
    "        super(CPNet, self).__init__()\n",
    "        self.base_net = PointNet()\n",
    "        self.loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.05)\n",
    "\n",
    "        \n",
    "    def forward(self, x1, x2, R, T):\n",
    "        \n",
    "        trans = torch.matmul(R, x1) + T.unsqueeze(2)\n",
    "        emb1 = self.base_net(trans)\n",
    "        emb2 = self.base_net(x2)\n",
    "        \n",
    "        dist = self.loss(emb1,emb2)\n",
    "\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPEvalNet(nn.Module):\n",
    "    def __init__(self, base_net, emb_dims=512):\n",
    "        super(CPEvalNet, self).__init__()\n",
    "        self.base_net = PointNet()\n",
    "        self.base_net.load_state_dict(base_net.state_dict())\n",
    "        for param in self.base_net:\n",
    "            param.require_grad = False\n",
    "        self.rotation = nn.Parameter(torch.Tensor(1,3,3))\n",
    "        self.translation = nn.Parameter(torch.Tensor(1,3))\n",
    "        nn.init.kaiming_uniform_(self.rotation, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.translation, a=math.sqrt(5))\n",
    "        self.loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.05)\n",
    "\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        trans = torch.matmul(self.rotation, x1) + self.translation.unsqueeze(2)\n",
    "        emb1 = self.base_net(trans)\n",
    "        emb2 = self.base_net(x2)\n",
    "        \n",
    "        dist = self.loss(emb1,emb2)\n",
    "\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_loss(output, target):\n",
    "    loss = torch.mean(output)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CPNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = dummy_loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "best=0\n",
    "\n",
    "def train_eval_convexity(model,device, train_loader,test_loader, optimizer,criterion, epoch, eval_mode='on'):\n",
    "    global best\n",
    "    model.train()\n",
    "    final_cal = nn.Sigmoid()\n",
    "    train_error_logs = []\n",
    "    t1 = datetime.now()\n",
    "    test_loss_log = []\n",
    "    test_acc_log = []\n",
    "    train_corrects = 0\n",
    "    \n",
    "#     for batch_idx, (src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba) in enumerate(train_loader):\n",
    "    for batch_idx, content in enumerate(train_loader):\n",
    "        content=(src, pointcloud1, pointcloud2, pointcloud3,\\\n",
    "                   mat1,mat2,mat3_0,mat3_1\n",
    "                   )\n",
    "        src=src.to(device)\n",
    "#         target = target.to(device)\n",
    "        pointcloud1=pointcloud1.to(device)\n",
    "        pointcloud2=pointcloud2.to(device)\n",
    "        pointcloud3=pointcloud3.to(device)\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output_train = model(src,pointcloud1,rotation_ab,translation_ab)\n",
    "        output_train = model(src,pointcloud2,rotation_ab,translation_ab)\n",
    "        output_train = model(src,pointcloud3,rotation_ab,translation_ab)\n",
    "        \n",
    "        \n",
    "        loss = criterion(output_train, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #pred_train = output_train.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        #train_corrects += pred_train.eq(target.view_as(pred_train)).sum().item()\n",
    "        train_error_logs.append(loss.item())\n",
    "        \n",
    "        if (batch_idx+0) % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime: {:.2f}'.format(\n",
    "                epoch, (batch_idx+0)* len(target), len(train_loader.dataset),\n",
    "                100. * (batch_idx+0) / len(train_loader), loss,(datetime.now()-t1).total_seconds()))\n",
    "\n",
    "        \n",
    "    print('Train Epoch: {} Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "                epoch, train_corrects, len(train_loader.dataset),\n",
    "                100. * train_corrects / len(train_loader.dataset)))\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba in enumerate(test_loader):\n",
    "            src = src.to(device)\n",
    "            target = target.to(device)\n",
    "            rotation_ab = rotation_ab.to(device)\n",
    "            translation_ab = translation_ab.to(device)\n",
    "            rotation_ba = rotation_ba.to(device)\n",
    "            translation_ba = translation_ba.to(device)\n",
    "            output_test = model(src,target,rotation_ab,translation_ab)\n",
    "            test_loss += criterion(output_test, target_test).item()  # sum up batch loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_loss_log.append(test_loss)\n",
    "    print('Test set: Average loss: {:.8f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss, correct_test, len(test_loader.dataset),\n",
    "            100. * correct_test / len(test_loader.dataset)))\n",
    "    return train_error_logs,test_loss_log,test_acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convex Training procedure\n",
    "train_time= []\n",
    "train_loss = []\n",
    "train_losses.append(train_loss)\n",
    "tests = []\n",
    "test_acc = []\n",
    "test_results_exp.append(tests)\n",
    "test_accs.append(test_acc)\n",
    "ratio = 0\n",
    "for epoch in range(1,30):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    t1 = datetime.now()\n",
    "    train_error,test_error,test_acc_this = train_eval_convexity(model,device, train_loader, test_loader, optimizer,criterion,epoch,'on')\n",
    "    train_loss.extend(train_error)\n",
    "    tests.extend(test_error)\n",
    "    test_acc.extend(test_acc_this)\n",
    "    train_time.append((datetime.now()-t1).total_seconds())\n",
    "    print((datetime.now()-t1).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Training\n",
    "criterion = dummy_loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "best=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 8, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4e69cd989599>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0madjust_learning_rate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtrain_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_acc_this\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_eval_icp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'on'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-4f07406f1c4a>\u001b[0m in \u001b[0;36mtrain_eval_icp\u001b[1;34m(model, device, train_loader, test_loader, optimizer, criterion, epoch, eval_mode)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_corrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation_ab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslation_ab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation_ba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslation_ba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meuler_ab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meuler_ba\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 8, got 4)"
     ]
    }
   ],
   "source": [
    "train_time= []\n",
    "train_loss = []\n",
    "train_losses.append(train_loss)\n",
    "tests = []\n",
    "test_acc = []\n",
    "test_results_exp.append(tests)\n",
    "test_accs.append(test_acc)\n",
    "ratio = 0\n",
    "for epoch in range(1,20):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    t1 = datetime.now()\n",
    "    train_error,test_error,test_acc_this = train_eval_icp(model,device, train_loader, test_loader, optimizer,criterion,epoch,'on')\n",
    "    train_loss.extend(train_error)\n",
    "    tests.extend(test_error)\n",
    "    test_acc.extend(test_acc_this)\n",
    "    train_time.append((datetime.now()-t1).total_seconds())\n",
    "    print((datetime.now()-t1).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n",
      "(3, 2048) (2048, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 8, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-41055dc7bb73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation_ab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslation_ab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation_ba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslation_ba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meuler_ab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meuler_ba\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 8, got 4)"
     ]
    }
   ],
   "source": [
    "for batch_idx, (src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba) in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_ab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
